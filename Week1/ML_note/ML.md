# ML第一周学习笔记

## 机器学习基本概念

机器学习（Machine Learning）就是寻找一个拟合某种分布情况的复杂函数的过程。

函数的输出可以有很多种，例如向量、矩阵、序列。输出也有很多种，例如仅输出一个数值（回归任务）、输出一个选择（分类任务），输出一句话（语言模型）。

- Regression 回归类型的函数：输入多个数值，输出一个数值就是回归任务。（？输出时连续的）
- Classification 分类函数：函数对通过对输入计算后得到离散的不同选择。（？输出时离散的）例如：图像分类、下棋中的下一步。
- Structured Learning 结构学习：创造有结构的事物（图像、文字等）的函数。

通过使用数据训练让机器学习学习要拟合的目标函数，训练数据根据是否有真实的标签（label），将训练分为监督训练（supervised-learning）和无监督训练、自监督训练等多种训练方法。

机器学习拟合目标函数的三个过程为：

1. 首先写出包含位置参数的函数或者模型（function with unknow parameters）
2. 根据训练的数据定义损失函数loss。表面上看loss度量了模型model与真实之间的距离，而loss本质上是模型参数的函数（ loss is L(Parameters of Model) ）。loss的数值反映了计算出loss的model参数的好坏程度。
3. 最优化optimization，找到能够使参数最小的那一组模型参数。在梯度下降过程中，随机初始化一组参数，然后根据loss对当前参数组的梯度并按照一定的学习率（learning rate）进行下降（例如梯度小于零，说明当前参数变大可以使Loss的值减小）其中参数的更新为（-lr*梯度），最后在根剧梯度下降结果更新模型的权重参数。

---------->为什么局部最小在深度学习中并不是要面临的最大的问题

线性模型很难拟合真实的情况，收到模型本身的很大的限制性，成为模型的偏移（bias）

对比线性模型，也可以使用sigmoid组成模型。其中sigmoid是$$y=c*\cfrac{1}{1+e^{-(b+wx_1)}}$$
若使用sigmoid函数代替简单的线性函数，模型有更强的拟合能力，代价是计算复杂度会变高。该模型的弹性更高，拟合能力更强，可变的空间更大。

将线性模型和非线性模型相结合后得到：$$y=b+\sum_i c_i\ sigmoid(b_i+\sum_j w_{ij}x_j)$$
其中$b_i+\sum_j w_{ij}x_j$相当与对一组输入进行一个线性变换（矩阵中的$\hat{W}\cdot\vec{x}+\vec{b}$），对于i组不同的线性变换结合得到不同的特征，在使用不同参数的sigmoid函数拟合，最后将i组组合相加并通过常数调节，使其拟合目标函数，通过这样的方式，即对多个输入按照不同组合线性变换，有通过sigmoid加强了模型的弹性（拟合能力）。设想如果没有sigmoid，相当于还是线性变化。而sigmoid在视频中出发点是拟合分段折线函数，两端是高低不同的水平线，中间直接连接，通过多段复杂的折线函数去拟合复杂函数。而sigmoid是与上述分段的折线函数很相似的一种函数。在优化的过程总，要注意的是，loss的梯度下降是对所有的模型参数进行梯度的计算更新模型的参数。

sigmod中函数计算复杂度较高，sigmoid在上述过程中本身的出发点是拟合分段折线函数

           ______
          /     
     ____/

该折线函数可以使用另外一种方式拟合，即两个ReLu结合。对比sigmoid函数与双ReLu的拟合方法，其公式如下：

sigmoid:$$y=b+\sum_i c_i\ sigmoid(b_i+\sum_j w_{ij}x_j)$$双ReLu：$$y=b+\sum_{2i} c_i\ max(0,b_i+\sum_j w_{ij}x_j)$$通过对比可以发现，增加模型非线性程度的激活函数，ReLu计算时更加快速。

至此得到了深度学习中神经网络的基本结构**线性变换+非线性激活**。神经网络本身是多层感知器结构，每层layer就是通过这种线性变换和非线性激活的结构组成的。深度学习中，除了输入和输出中的结构均成为隐藏层（hidden layer）。

过拟合（overfitting）只深度学习网络在训练集上的效果变好，但是在测试集上的效果会变差。

在优化训练中，将数据集划分为多个batch每个batch更新一次参数，对所有数据进行多轮次的计算epoch（即每个batch被计算epoch次）
